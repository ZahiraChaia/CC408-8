# -*- coding: utf-8 -*-
"""TP4 AÑOS ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QfszFUjYIFapYMwWAzrNdvNApW4AgeK_

# PARTE 1: Análisis de la base de hogares y tipo de ocupación

# Ejercicio 1
"""

# Importamos librerias necesarias
!pip install --upgrade pandas pyreadstat

import pyreadstat
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from google.colab import drive

"""### Cargamos las bases"""

hogar_2004 = pd.read_stata("/content/Hogar_t104.dta") # leemos archivo 2004
# Verificar que se cargó correctamente
print(hogar_2004.shape)  # Muestra el número de filas y columnas

hogar_2024 = pd.read_excel('/content/usu_hogar_T124.xlsx') # leemos archivo 2024
# Verificar que se cargó correctamente
print(hogar_2024.shape)  # Muestra el número de filas y columnas

individual_2004 = pd.read_stata('/content/Individual_t104.dta') # leemos archivo 2024
# Verificar que se cargó correctamente
print(individual_2004.shape)  # Muestra el número de filas y columnas

individual_2024 = pd.read_excel('/content/usu_individual_T124.xlsx') # leemos archivo 2024
# Verificar que se cargó correctamente
print(individual_2024.shape)  # Muestra el número de filas y columnas

"""### Dropeamos != Gran Buenos Aires

"""

hogar_2004_df= hogar_2004.drop(hogar_2004[hogar_2004["region"] != "Gran Buenos Aires"].index, axis=0) # eliminamos datos que no corresponden a GCBA

# Contar la cantidad de datos que quedaron después del filtrado
print(f"Cantidad de datos después del filtrado: {len(hogar_2004_df)}")

hogar_2024_df=hogar_2024.drop(hogar_2024[hogar_2024["REGION"] != 1].index, axis=0) # eliminamos datos que no corresponden a GCBA

# Contar la cantidad de datos que quedaron después del filtrado
print(f"Cantidad de datos después del filtrado: {len(hogar_2024_df)}")

individual_2004_df= individual_2004.drop(individual_2004[individual_2004["region"] != "Gran Buenos Aires"].index, axis=0) # eliminamos datos que no corresponden a GCBA

# Contar la cantidad de datos que quedaron después del filtrado
print(f"Cantidad de datos después del filtrado: {len(individual_2004_df)}")

individual_2024_df= individual_2024.drop(individual_2024[individual_2024["REGION"] != 1].index, axis=0) # eliminamos datos que no corresponden a GCBA

# Contar la cantidad de datos que quedaron después del filtrado
print(f"Cantidad de datos después del filtrado: {len(individual_2024_df)}")

"""# Ejercicio 2

### Merge 2004
"""

# Cambiar los nombres de las columnas a minúsculas
individual_2004_df.columns = individual_2004_df.columns.str.lower()
hogar_2004_df.columns = hogar_2004_df.columns.str.lower()

df_merge04 = pd.merge(individual_2004_df, hogar_2004_df, on=['codusu', 'nro_hogar'], how='outer')

"""### Merge 2024"""

# Cambiar los nombres de las columnas a minúsculas
individual_2024_df.columns = individual_2024_df.columns.str.lower()
hogar_2024_df.columns = hogar_2024_df.columns.str.lower()

df_merge24 = pd.merge(individual_2024_df, hogar_2024_df, on=['codusu', 'nro_hogar'], how='outer')

"""# Ejercicio 3"""

# Decidimos seleccionar algunas columnas relevantes
columnas_seleccionadas = ['ch04', 'ch06', 'ch07', 'ch08', 'ch09', 'nivel_ed', 'estado', 'cat_inac', "v5","v6","v12","v15","ix_tot", "iv1","iv2","iv5","iv6", "iv8", "iv12_3", "ii1",  "codusu"] # agregamos ch09
df_merge04 = df_merge04[columnas_seleccionadas]
df_merge24 = df_merge24[columnas_seleccionadas]

"""## datos duplicados"""

# Contar datos antes de eliminar duplicados
datos_antes = len(df_merge04)

# Eliminar filas duplicadas basadas en todas las columnas
df_merge04 = df_merge04.drop_duplicates()

# Contar datos después de eliminar duplicados
datos_despues = len(df_merge04)

# Calcular y mostrar la cantidad de datos que se pierden
datos_perdidos = datos_antes - datos_despues
print(f"Cantidad de datos eliminados por duplicados: {datos_perdidos}")

# Restablecer el índice después de eliminar duplicados (opcional)
df_merge04 = df_merge04.reset_index(drop=True)

# Contar datos antes de eliminar duplicados
datos_antes24 = len(df_merge24)

# Eliminar filas duplicadas basadas en todas las columnas
df_merge24 = df_merge24.drop_duplicates()

# Contar datos después de eliminar duplicados
datos_despues24 = len(df_merge24)

# Calcular y mostrar la cantidad de datos que se pierden
datos_perdidos24 = datos_antes24 - datos_despues24
print(f"Cantidad de datos eliminados por duplicados: {datos_perdidos24}")

# Restablecer el índice después de eliminar duplicados (opcional)
df_merge24 = df_merge24.reset_index(drop=True)

"""## Datos faltantes  NS/nr"""

df_merge04.isna().sum() #contamos NA
df_merge24.isna().sum() #contamos NA

"""#### 2004"""

# DATOS FALTANTES Y NS/NR

df_merge04.isna().sum() #contamos NA

# evaluamos si en cada columnas hay datos clasificados como Ns/Nr
def evaluar_ns_nr(df):
    """
    Evalúa cada columna del DataFrame para verificar si hay algún valor 'Ns./Nr.'.
    """
    for columna in df.columns:
        if df[columna].isin(["Ns./Nr.", "NS./NR.", 0]).any():
            print(f"La columna '{columna}' CONTIENE {len(df[df[columna] == 'Ns./Nr.'])} datos 'Ns./Nr.'.")
        else:
            print(f"La columna '{columna}' no contiene datos 'Ns./Nr.'.")

evaluar_ns_nr(df_merge04)

# Columnas a evaluar para valores '9'
columnas_a_evaluar = ["ch08", "ch09", "v5", "v6", "v12", "v15", "iv12_3", "iv8"] # NO filtramos en 'ch06', 'ii1', 'ix_tot' porque son numericas

for columna in columnas_seleccionadas:
    # Filtrar filas donde el valor sea 'Ns./Nr.'
    cantidad_na = len(df_merge04[df_merge04[columna] == "Ns./Nr."])
    total = len(df_merge04[columna])

    # Filtrar filas donde el valor sea 0
    cantidad_0 = len(df_merge04[df_merge04[columna] == "Ns./Nr."])
    total = len(df_merge04[columna])

    # Imprimir resultados
    print(f"La cantidad de NA en {columna} es {cantidad_na}")
    print(f"La proporción de NA en {columna} es {cantidad_na / total:.4f}")

    print(f"La cantidad de 0 en {columna} es {cantidad_0}")
    print(f"La proporción de 0 en {columna} es {cantidad_0 / total:.4f}\n")

    # Filtrar el DataFrame para eliminar filas con valor '9' en esta columna
    df_merge04 = df_merge04[df_merge04[columna] != "Ns./Nr."]
    df_merge04 = df_merge04[df_merge04[columna] != "Ns./Nr."]

"""####2024"""

def evaluar_9(df):
    """
    Evalúa cada columna del DataFrame para verificar si hay algún valor 9 ('Ns./Nr.' o 'NS./NR.').
    """
    for columna in df.columns:
      try:
        num_valores_9 = (df[columna] == 9).sum()  # Contar valores igual a 9
        if num_valores_9 > 0:
          print(f"La columna '{columna}' CONTIENE {num_valores_9} datos '9' ('Ns./Nr.').")
        else:
          print(f"La columna '{columna}' no contiene datos '9'.")
      except Exception as e:
        print(f"No se pudo evaluar la columna '{columna}' debido a: {e}")

# Llamamos a la función para evaluar
evaluar_9(df_merge24)

# Columnas a evaluar para valores '9'
columnas_a_evaluar = ["ch07", "ch08", "ch09", "v5", "v6", "v12", "v15", "iv12_3", "iv8"] # NO filtramos en 'ch06', 'ii1', 'ix_tot' porque son numericas

for columna in columnas_a_evaluar:
    # Filtrar filas donde el valor sea '9'
    cantidad_na = len(df_merge24[df_merge24[columna] == 9])
    total = len(df_merge24[columna])

    # Filtrar filas donde el valor sea 0
    cantidad_0 = len(df_merge24[df_merge24[columna] == 0])
    total = len(df_merge24[columna])

    # Imprimir resultados
    print(f"La cantidad de NA en {columna} es {cantidad_na}")
    print(f"La proporción de NA en {columna} es {cantidad_na / total:.4f}")

    print(f"La cantidad de 0 en {columna} es {cantidad_0}")
    print(f"La proporción de 0 en {columna} es {cantidad_0 / total:.4f}\n")

    # Filtrar el DataFrame para eliminar filas con valor '9' en esta columna
    df_merge24 = df_merge24[df_merge24[columna] != 9]
    df_merge24 = df_merge24[df_merge24[columna] != 0]

"""## valores inusuales y outiliers

#### Edad
"""

df_merge04["ch06"]

df_merge24["ch06"].unique()

# Convertimos todos los valores de "CH06" a numéricos en 2004
df_merge04["ch06"] = df_merge04["ch06"].replace({"Menos de 1 año": 1, "98 y más años": 98})  # Reemplazamos el string "Menos de 1 año" por 1 y "98 y más años" por 98

# Convertimos la columna a numérica para asegurar la consistencia de los datos
df_merge04["ch06"] = df_merge04["ch06"].astype(int)

# Observamos ch06 (edad) en 2004
plt.hist(df_merge04["ch06"],bins=30, edgecolor='black', color='pink')
plt.xlabel('Edad')
plt.ylabel('Datos')
plt.title("Histograma de edades 2004", fontweight="bold")
# Mostrar el gráfico
plt.show()

# Evaluamos datos negativos
print(f"Los datos menores a 0 son {len(df_merge04[df_merge04['ch06']<0])}")
print(f"Esto representa un {len(df_merge04[df_merge04['ch06']<0]) / len(df_merge04)*100}% de los datos")

# Observamos ch06 (edad) en 2024
plt.hist(df_merge24["ch06"],bins=30, edgecolor='black', color='skyblue')
plt.xlabel('Edad')
plt.ylabel('Datos')
plt.title("Histograma de edades 2024", fontweight="bold")
# Mostrar el gráfico
plt.show()

# Evaluamos datos negativos
print(f"Los datos menores a 0 son {len(df_merge24[df_merge24['ch06']<0])}")
print(f"Esto representa un {len(df_merge24[df_merge24['ch06']<0]) / len(df_merge24)*100}% de los datos")

# filtramos valores negativos
df_merge24 = df_merge24[df_merge24['ch06']>0]

"""#### ii1"""

# Observamos ii1 en 2004
plt.hist(df_merge04["ii1"],bins=30, edgecolor='black', color='pink')
plt.xlabel('ii1')
plt.ylabel('Datos')
plt.title("Histograma de habitaciones 2004", fontweight="bold")
# Mostrar el gráfico
plt.show()

# Evaluamos datos negativos
print(f"Los datos menores a 0 son {len(df_merge04[df_merge04['ii1']<0])}")
print(f"Esto representa un {len(df_merge04[df_merge04['ii1']<0]) / len(df_merge04)*100}% de los datos")

# Observamos ii1 en 2024
plt.hist(df_merge24["ii1"],bins=30, edgecolor='black', color='skyblue')
plt.xlabel('ii1')
plt.ylabel('Datos')
plt.title("Histograma de habitaciones 2024", fontweight="bold")
# Mostrar el gráfico
plt.show()

# Evaluamos datos negativos
print(f"Los datos menores a 0 son {len(df_merge24[df_merge24['ii1']<0])}")
print(f"Esto representa un {len(df_merge24[df_merge24['ii1']<0]) / len(df_merge24)*100}% de los datos")

"""#### ix_tot"""

# Observamos ix_tot en 2004
plt.hist(df_merge04["ix_tot"],bins=30, edgecolor='black', color='pink')
plt.xlabel('ix_tot')
plt.ylabel('Datos')
plt.title("Histograma de miembros del hogar 2004", fontweight="bold")
# Mostrar el gráfico
plt.show()

# Evaluamos datos negativos
print(f"Los datos menores a 0 son {len(df_merge04[df_merge04['ix_tot']<0])}")
print(f"Esto representa un {len(df_merge04[df_merge04['ix_tot']<0]) / len(df_merge04)*100}% de los datos")

# Observamos ii1 en 2024
plt.hist(df_merge24["ix_tot"],bins=30, edgecolor='black', color='skyblue')
plt.xlabel('ix_tot')
plt.ylabel('Datos')
plt.title("Histograma de miembros del hogar 2024", fontweight="bold")
# Mostrar el gráfico
plt.show()

# Evaluamos datos negativos
print(f"Los datos menores a 0 son {len(df_merge24[df_merge24['ix_tot']<0])}")
print(f"Esto representa un {len(df_merge24[df_merge24['ix_tot']<0]) / len(df_merge24)*100}% de los datos")

"""## Encoding binarias

#### 2004
"""

def columnas_binarias(df, columnas):
    """
    Identifica columnas binarias (con exactamente dos valores únicos) en un DataFrame.
    """
    columnas_binarias = []
    for columna in columnas:
        # Obtenemos los valores únicos no nulos de la columna
        valores_unicos = df[columna].unique()

        # Si la columna tiene exactamente dos valores únicos, se considera binaria
        if len(valores_unicos) == 2:
            columnas_binarias.append(columna)

    return columnas_binarias

# lista de columans
columnas_evaluar_binarias = df_merge04.columns.tolist()
columnas_evaluar_binarias

# seleccionar binarias
columnas_binarias(df_merge04, columnas_evaluar_binarias)

# Lista de columnas a transformar (Si/No)
columnas_si_no = ['v5', 'v6', 'v12', 'v15', 'iv5', 'iv8', 'iv12_3']

# Transformar columnas en el DataFrame
for columna in columnas_si_no:
    if columna in df_merge04.columns:
        # Verificar si la columna es categórica
        if isinstance(df_merge04[columna].dtype, pd.CategoricalDtype):
            # Convertir las categorías a strings y asegurarnos de que sean únicas
            df_merge04[columna] = df_merge04[columna].astype(str).str.strip()

            # Reemplazar valores categóricos a binarios
            df_merge04[columna] = df_merge04[columna].replace({'Si': 1, 'Sí': 1, 'No': 0})
        else:
            # Si no es categórica, hacer el reemplazo directamente
            df_merge04[columna] = df_merge04[columna].replace({'Si': 1, 'Sí': 1, 'No': 0})

        # Convertir los valores finales a tipo entero
        df_merge04[columna] = pd.to_numeric(df_merge04[columna], errors='coerce').fillna(0).astype(int)

# Verificar el resultado
print(df_merge04[columnas_si_no].head())

# Mapeo para la columna "ch04" (Sexo)
ch04_mapping = {
    "Varón":0,
    "Mujer":1
}
df_merge04["ch04"] = df_merge04["ch04"].replace(ch04_mapping)

"""#### 2024

"""

def columnas_binarias(df, columnas):
    """
    Identifica columnas binarias (con exactamente dos valores únicos) en un DataFrame.
    """
    columnas_binarias = []
    for columna in columnas:
        # Obtenemos los valores únicos no nulos de la columna
        valores_unicos = df[columna].unique()

        # Si la columna tiene exactamente dos valores únicos, se considera binaria
        if len(valores_unicos) == 2:
            columnas_binarias.append(columna)

    return columnas_binarias

# lista de columans
columnas_evaluar_binarias24 = df_merge24.columns.tolist()
columnas_evaluar_binarias24

# seleccionar binarias
columnas_binarias(df_merge24, columnas_evaluar_binarias24)

# Lista de columnas a transformar (2/1)
columnas_si_no = ['ch04', 'v5', 'v6', 'v12', 'v15', 'iv5', 'iv8', 'iv12_3']  # Cambia por tus columnas

# Aplicar el mapeo de 2 a 0 y 1 a 1
for columna in columnas_si_no:
    if isinstance(df_merge24[columna].dtype, pd.CategoricalDtype):
        # Si la columna es categórica, renombramos las categorías
        df_merge24[columna] = df_merge24[columna].cat.rename_categories({
            2: 0,  # Reemplazar 2 por 0
            1: 1   # Dejar 1 igual
        })
    else:
        # Si la columna no es categórica, reemplazamos directamente
        df_merge24[columna] = df_merge24[columna].replace({2: 0, 1: 1})

    # Convertir la columna a tipo binario (int) después del reemplazo
    df_merge24[columna] = df_merge24[columna].astype(int)

# Verificar el resultado
print(df_merge24[columnas_si_no].head())

"""# Ejercicio 4

## Maximo nivel educativo hogar
"""

df_merge04["nivel_ed"].unique()

# Modificar directamente las categorías de la columna categórica
df_merge04["nivel_ed"] = df_merge04["nivel_ed"].cat.rename_categories({
    'Primaria Incompleta (incluye educación especial)': 'Primaria Incompleta'
})

# Maximo nivel educativo hogar

# 2004
# Definir una jerarquía para los niveles educativos
jerarquia_niveles = {
    'Sin instrucción': 0,
    'Primaria Incompleta': 1,
    'Primaria Completa': 2,
    'Secundaria Incompleta': 3,
    'Secundaria Completa': 4,
    'Superior Universitaria Incompleta': 5,
    'Superior Universitaria Completa': 6
}

# Mapear los niveles educativos a valores numéricos
df_merge04['nivel_ed_numeric04'] = df_merge04['nivel_ed'].map(jerarquia_niveles)

# Calcular el nivel educativo máximo por hogar
nivel_maximo_hogar04 = df_merge04.groupby('codusu')['nivel_ed_numeric04'].max().reset_index()

# Renombrar la columna calculada
nivel_maximo_hogar04.rename(columns={'nivel_ed_numeric04': 'nivel_ed_maximo04'}, inplace=True)

# Unir con el DataFrame original
df_merge04 = df_merge04.merge(nivel_maximo_hogar04, on='codusu', how='left')

# Imprimir
print(df_merge04.head())

df_merge24["nivel_ed"].unique()

# 2024

# Modificar las categorías de la columna 'nivel_ed'
# Definir una jerarquía para los niveles educativos
jerarquia_niveles_2024 = {
    7: 0,
    1: 1,
    2: 2,
    3: 3,
    4: 4,
    5: 5,
    6: 6
}

# Mapear los niveles educativos a valores numéricos
df_merge24['nivel_ed_numeric2024'] = df_merge24['nivel_ed'].map(jerarquia_niveles_2024)

# Calcular el nivel educativo máximo por hogar
nivel_maximo_hogar24 = df_merge24.groupby('codusu')['nivel_ed_numeric2024'].max().reset_index()

# Renombrar la columna calculada
nivel_maximo_hogar24.rename(columns={'nivel_ed_numeric2024': 'nivel_ed_maximo24'}, inplace=True)

# Unir con el DataFrame original
df_merge24 = df_merge24.merge(nivel_maximo_hogar24, on='codusu', how='left')

# Imprimir el resultado
print(df_merge24.head())

"""## Indice de ayuda externa

#### 2004
"""

# Crear el índice de ayuda externa: Sumar los valores de las tres columnas
df_merge04['indice_ayuda_externa04'] = df_merge04['v5'] + df_merge04['v6'] + df_merge04['v12']

# Imprimir las primeras filas para verificar el resultado
print(df_merge04[['v5', 'v6', 'v12', 'indice_ayuda_externa04']].head())

# Contar los valores únicos en la columna 'indice_ayuda_externa04'
print(df_merge04['indice_ayuda_externa04'].value_counts())

"""#### 2024"""

# Crear el índice de ayuda externa: Sumar los valores de las tres columnas
df_merge24['indice_ayuda_externa24'] = df_merge24['v5'] + df_merge24['v6'] + df_merge24['v12']

# Imprimir las primeras filas para verificar el resultado
print(df_merge24[['v5', 'v6', 'v12', 'indice_ayuda_externa24']].head())

# Contar los valores únicos en la columna 'indice_ayuda_externa24'
print(df_merge24['indice_ayuda_externa24'].value_counts())

"""## Cantidad de menores de 16 por hogar

#### 2004
"""

# Crear una nueva columna que indique si la persona es menor de 16 años
df_merge04['menor_de_16'] = (df_merge04['ch06'] < 16).astype(int)

# Calcular la cantidad de menores de 16 por hogar
cantidad_menores_16_por_hogar04 = df_merge04.groupby('codusu')['menor_de_16'].sum().reset_index()

# Renombrar la columna calculada
cantidad_menores_16_por_hogar04.rename(columns={'menor_de_16': 'cantidad_menores_16'}, inplace=True)

# Unir con el DataFrame original para obtener la cantidad de menores de 16 por hogar
df_merge04 = df_merge04.merge(cantidad_menores_16_por_hogar04, on='codusu', how='left')

# Imprimir el resultado
print(df_merge04[['codusu', 'cantidad_menores_16']].head())

"""#### 2024"""

# Crear una nueva columna que indique si la persona es menor de 16 años
df_merge24['menor_de_16'] = (df_merge24['ch06'] < 16).astype(int)

# Calcular la cantidad de menores de 16 por hogar
cantidad_menores_16_por_hogar24 = df_merge24.groupby('codusu')['menor_de_16'].sum().reset_index()

# Renombrar la columna calculada
cantidad_menores_16_por_hogar24.rename(columns={'menor_de_16': 'cantidad_menores_16'}, inplace=True)

# Unir con el DataFrame original para obtener la cantidad de menores de 16 por hogar
df_merge24 = df_merge24.merge(cantidad_menores_16_por_hogar24, on='codusu', how='left')

# Imprimir el resultado
print(df_merge24[['codusu', 'cantidad_menores_16']].head())

"""# Ejercicio 5

"""

# 2004
# Establecer estilo visual con paleta más suave
sns.set(style="whitegrid")

# Variables de interés para predecir la desocupación
variables_relevantes = ['ch06', 'ch09', 'v5']

# Estadísticas descriptivas de las variables
estadisticas = df_merge04[variables_relevantes].describe(include='all')

print("Estadísticas Descriptivas de Variables Relevantes para Predecir la Desocupación 2004")
print(estadisticas)
print("\n")

# 2024
# Establecer estilo visual con paleta más suave
sns.set(style="whitegrid")

# Estadísticas descriptivas de las variables en df_merge24
estadisticas24 = df_merge24[variables_relevantes].describe(include='all')

print("Estadísticas Descriptivas de Variables Relevantes para Predecir la Desocupación 2024")
print(estadisticas24)

"""### Nivel educativo grafico"""

# Establecer estilo visual con paleta más suave
sns.set(style="whitegrid")

# Crear el gráfico de barras sin el warning
plt.figure(figsize=(10, 6))
sns.countplot(data=df_merge04, x='nivel_ed', order=df_merge04['nivel_ed'].value_counts().index, palette='Set2')

# Añadir título y etiquetas
plt.title('Distribución de Nivel Educativo 2004', fontsize=16)
plt.xlabel('Nivel Educativo', fontsize=12)
plt.ylabel('Cantidad de Personas', fontsize=12)

# Rotar etiquetas del eje X para mejor visibilidad
plt.xticks(rotation=45, ha='right')

# Mostrar el gráfico
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Diccionario de valores numéricos y sus etiquetas correspondientes
diccionario_niveles = {
    1: 'Primaria Incompleta',
    2: 'Primaria Completa',
    3: 'Secundaria Incompleta',
    4: 'Secundaria Completa',
    5: 'Superior Universitaria Incompleta',
    6: 'Superior Universitaria Completa',
    7: 'Sin instrucción'
}

# Establecer estilo visual con paleta más suave
sns.set(style="whitegrid")

# Crear el gráfico de barras con orden numérico ascendente
plt.figure(figsize=(12, 8))
ax = sns.countplot(
    data=df_merge24,
    x='nivel_ed',
    order=sorted(df_merge24['nivel_ed'].unique()),
    palette='Set2'
)

# Añadir las etiquetas con los valores directamente sobre las barras
for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{height}',  # El valor de la barra
                (p.get_x() + p.get_width() / 2., height),  # Coordenadas
                ha='center', va='bottom', fontsize=10, color='black',
                xytext=(0, 5), textcoords='offset points')  # Desplazamiento de la etiqueta

# Reemplazar las etiquetas del eje X con las descripciones del diccionario
ax.set_xticklabels([diccionario_niveles.get(x, x) for x in sorted(df_merge24['nivel_ed'].unique())])

# Añadir título y etiquetas de los ejes
plt.title('Distribución de Nivel Educativo 2024', fontsize=18)
plt.xlabel('Nivel Educativo', fontsize=14)
plt.ylabel('Cantidad de Personas', fontsize=14)

# Rotar etiquetas del eje X a 45 grados para mejor visibilidad
plt.xticks(rotation=45, ha='right')

# Mostrar el gráfico
plt.tight_layout()
plt.show()

"""### Edad gráfico"""

#2004
plt.hist(df_merge04["ch06"],bins=30, edgecolor='black', color='pink')
plt.xlabel('Edad')
plt.ylabel('Datos')
plt.title("Histograma de edades 2004", fontweight="bold")
# Mostrar el gráfico
plt.show()

# Observamos ch06 (edad) en 2024
plt.hist(df_merge04["ch06"],bins=30, edgecolor='black', color='skyblue')
plt.xlabel('Edad')
plt.ylabel('Datos')
plt.title("Histograma de edades 2024", fontweight="bold")
# Mostrar el gráfico
plt.show()

# Comparar distribuciones de 'ch06' (Edad) entre 2004 y 2024
plt.figure(figsize=(12, 6))
sns.kdeplot(df_merge04['ch06'], label='2004', shade=True, color='blue', alpha=0.5)
sns.kdeplot(df_merge24['ch06'], label='2024', shade=True, color='red', alpha=0.5)
plt.title('Distribución de Edad en 2004 vs 2024', fontsize=16)
plt.xlabel('Edad', fontsize=12)
plt.ylabel('Densidad', fontsize=12)
plt.legend()
plt.tight_layout()
plt.show()

"""### alfabetización"""

# Configuración del estilo del gráfico
sns.set(style="whitegrid")

# Crear el gráfico de barras con la columna corregida
plt.figure(figsize=(10, 6))
ax = sns.countplot(
    data=df_merge04,
    x='ch09',
    order=df_merge04['ch09'].value_counts().index,
    palette='Set2'
)

# Calcular el porcentaje para cada categoría
total = len(df_merge04)
for p in ax.patches:
    height = p.get_height()
    percentage = (height / total) * 100
    ax.annotate(f'{percentage:.2f}%',
                (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center',
                fontsize=10, color='black',
                xytext=(0, 5), textcoords='offset points')

# Añadir título y etiquetas
plt.title('Distribución de Personas por ch09 (2024)', fontsize=16)
plt.xlabel('Estado de ch09 (1=Sí, 0=No)', fontsize=12)
plt.ylabel('Cantidad de Personas analfabetas en 2004', fontsize=12)

# Rotar etiquetas del eje X para mejor visibilidad
plt.xticks(ha='right')

# Mostrar el gráfico
plt.tight_layout()
plt.show()

# Configuración del estilo del gráfico
sns.set(style="whitegrid")

# Crear el gráfico de barras con etiquetas corregidas
plt.figure(figsize=(10, 6))
ax = sns.countplot(
    data=df_merge24,
    x='ch09',
    order=df_merge24['ch09'].value_counts().index,
    palette='Set2'
)

# Calcular el porcentaje para cada categoría
total = len(df_merge24)
for p in ax.patches:
    height = p.get_height()
    percentage = (height / total) * 100
    ax.annotate(f'{percentage:.2f}%',
                (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center',
                fontsize=10, color='black',
                xytext=(0, 5), textcoords='offset points')

# Añadir título y etiquetas
plt.title('Distribución de Personas por ch09 (2024)', fontsize=16)
plt.xlabel('Estado de ch09 (1=No, 0=Sí)', fontsize=12)
plt.ylabel('Cantidad de Personas analfabetas en 2024', fontsize=12)

# Rotar etiquetas del eje X para mejor visibilidad
plt.xticks(ha='right')

# Mostrar el gráfico
plt.tight_layout()
plt.show()

"""### subsidio o ayuda social (V5)"""

# 2004
# Establecer estilo visual
sns.set(style="whitegrid")

# Crear el gráfico de barras
plt.figure(figsize=(10, 6))
ax = sns.countplot(data=df_merge04, x='v5', order=df_merge04['v5'].value_counts().index, palette='Set2')

# Calcular el porcentaje para cada categoría
total = len(df_merge04)
for p in ax.patches:
    height = p.get_height()
    percentage = (height / total) * 100
    ax.annotate(f'{percentage:.2f}%',
                (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center',
                fontsize=10, color='black',
                xytext=(0, 5), textcoords='offset points')

# Añadir título y etiquetas
plt.title('Distribución de V5', fontsize=16)
plt.xlabel('Distribución de V5', fontsize=12)
plt.ylabel('Cantidad de Persona con ayuda social en 2004', fontsize=12)

# Rotar etiquetas del eje X para mejor visibilidad
plt.xticks(rotation=0, ha='right')

# Mostrar el gráfico
plt.tight_layout()
plt.show()

2024
# Establecer estilo visual
sns.set(style="whitegrid")

# Crear el gráfico de barras
plt.figure(figsize=(10, 6))
ax = sns.countplot(data=df_merge24, x='v5', order=df_merge04['v5'].value_counts().index, palette='Set2')

# Calcular el porcentaje para cada categoría
total = len(df_merge24)
for p in ax.patches:
    height = p.get_height()
    percentage = (height / total) * 100
    ax.annotate(f'{percentage:.2f}%',
                (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center',
                fontsize=10, color='black',
                xytext=(0, 5), textcoords='offset points')

# Añadir título y etiquetas
plt.title('Distribución de V5', fontsize=16)
plt.xlabel('Distribución de V5', fontsize=12)
plt.ylabel('Cantidad de Persona con ayuda social en 2024', fontsize=12)

# Rotar etiquetas del eje X para mejor visibilidad
plt.xticks(rotation=0, ha='right')

# Mostrar el gráfico
plt.tight_layout()
plt.show()

"""## Otros análisis"""

# 2004
# Crear una tabla de contingencia (contando combinaciones de nivel_ed y v5)
tabla_contingencia = pd.crosstab(df_merge04['nivel_ed'], df_merge04['v5'])

# Mostrar la tabla de contingencia
print(tabla_contingencia)
print("\n")

# Calcular la probabilidad de que una persona en cada nivel educativo tenga 'Sí' en v5
probabilidad_si = tabla_contingencia[1] / tabla_contingencia.sum(axis=1)

# Calcular la probabilidad de que una persona en cada nivel educativo tenga 'No' en v5
probabilidad_no = tabla_contingencia[0] / tabla_contingencia.sum(axis=1)

# Mostrar las probabilidades
print("Probabilidad de 'Sí' en subsidios por nivel educativo 2004:")
print(probabilidad_si)
print("\n")

print("\nProbabilidad de 'No' en subsidios por nivel educativo 2004:")
print(probabilidad_no)

# 2024
# Crear una tabla de contingencia (contando combinaciones de nivel_ed y v5)
tabla_contingencia = pd.crosstab(df_merge24['nivel_ed'], df_merge04['v5'])

# Mostrar la tabla de contingencia
print(tabla_contingencia)
print("\n")

# Calcular la probabilidad de que una persona en cada nivel educativo tenga 'Sí' en v5
probabilidad_si = tabla_contingencia[1] / tabla_contingencia.sum(axis=1)

# Calcular la probabilidad de que una persona en cada nivel educativo tenga 'No' en v5
probabilidad_no = tabla_contingencia[0] / tabla_contingencia.sum(axis=1)

# Mostrar las probabilidades
print("Probabilidad de 'Sí' en subsidios por nivel educativo 2024:")
print(probabilidad_si)
print("\n")

print("\nProbabilidad de 'No' en subsidios por nivel educativo 2024:")
print(probabilidad_no)

print("\n")
print("Diccionario de valores numéricos:")
print("1 = Primaria Incompleta")
print("2 = Primaria Completa")
print("3 = Secundaria Incompleta")
print("4 = Secundaria Completa")
print("5 = Superior Universitaria Incompleta")
print("6 = Superior Universitaria Completa")
print("7 = Sin instrucción")

"""# PARTE 2: Clasificación y regularización

## Ejercicio 1

### Encoding
"""

# Columna llamada "desocupado" para analisis posterior
df_merge04["desocupado"] = (df_merge04["estado"] == "Desocupado").astype(int)
df_merge04["desocupado"].unique()

# Contar la cantidad de personas desocupadas en 2004
cantidad_desocupados = (df_merge04["desocupado"] == 1).sum()
print(f"Cantidad de personas desocupadas en 2004: {cantidad_desocupados}")

df_merge04_clasific = df_merge04.drop(["codusu","estado"], axis=1, errors='ignore')

# Excluimos las variables numéricas y binarias
columnas_a_codificar = ['ch07',"ch09", 'ch08', 'nivel_ed', 'cat_inac', "iv1","iv2","iv6"]

# Aplicamos One-Hot Encoding solo a las columnas seleccionadas
df_merge_encoded04 = pd.get_dummies(df_merge04_clasific, columns=columnas_a_codificar, drop_first=False)

# Ver el resultado
print(df_merge_encoded04.head())

# Columna llamada "desocupado" para analisis posterior
df_merge24["desocupado"] = (df_merge24["estado"] == 2).astype(int)
df_merge24["desocupado"].unique()

# Contar la cantidad de personas desocupadas en 2004
cantidad_desocupados = (df_merge24["desocupado"] == 1).sum()
print(f"Cantidad de personas desocupadas en 2024: {cantidad_desocupados}")

df_merge24_clasific = df_merge24.drop(["codusu","estado"], axis=1, errors='ignore')

# Excluimos las variables numéricas y binarias

# Aplicamos One-Hot Encoding solo a las columnas seleccionadas (excluyendo 'ch06')
df_merge_encoded24 = pd.get_dummies(df_merge24_clasific, columns=columnas_a_codificar, drop_first=False)

# Ver el resultado
print(df_merge_encoded24.head())

"""### Partimos Bases"""

df_merge_encoded04.columns

# Partimos la base año 2004

from sklearn.model_selection import train_test_split

# Separar la variable dependiente
y = df_merge_encoded04["desocupado"]
X = df_merge_encoded04.drop(columns=['desocupado'])

# Agregar la columna de unos para el intercepto en X
X = np.hstack((np.ones((X.shape[0], 1)), X))

# Dividir en entrenamiento (70%) y prueba (30%) con semilla 101
X_train04, X_test04, y_train04, y_test04 = train_test_split(X, y, test_size=0.3, random_state=101)

# Verificamos que se cumplan dimensiones

cantidad_total04 = X.shape[0]
cantidad_train04 = X_train04.shape[0]
cantidad_test04 = X_test04.shape[0]

print(f"Proporción entrenamiento 2004: {round(cantidad_train04 / cantidad_total04, 2)*100}%")
print(f"Proporción prueba 2004: {round(cantidad_test04  / cantidad_total04, 2)*100}%")

# Partimos la base año 2024

# Separar la variable dependiente
y = df_merge_encoded24["desocupado"]
X = df_merge_encoded24.drop(columns=['desocupado'])

# Agregar la columna de unos para el intercepto en X
X = np.hstack((np.ones((X.shape[0], 1)), X))

# Dividir en entrenamiento (70%) y prueba (30%) con semilla 101
X_train24, X_test24, y_train24, y_test24 = train_test_split(X, y, test_size=0.3, random_state=101)

# Verificamos que se cumplan dimensiones

cantidad_total24 = X.shape[0]
cantidad_train24 = X_train24.shape[0]
cantidad_test24 = X_test24.shape[0]

print(f"Proporción entrenamiento 2024: {round(cantidad_train24 / cantidad_total24, 2)*100}%")
print(f"Proporción prueba 2024: {round(cantidad_test24  / cantidad_total24, 2)*100}%")

"""

## Ejercicio 4"""

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, classification_report
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

# Verifica la distribución de clases en los datos
print(y_train04.value_counts())
print(y_test04.value_counts())

# Crear el escalador
sc = StandardScaler()

# Escalar sin usar índices ni columnas
X_train04_sc = pd.DataFrame(sc.fit_transform(X_train04))
X_test04_sc = pd.DataFrame(sc.transform(X_test04))

# Parámetros comunes
penalizaciones = ['l1', 'l2']  # L1 y L2
lambda_value = 1  # Corresponde a 'C = 1/lambda' en scikit-learn

for penalty in penalizaciones:
    print(f"\n--- Regresión Logística con Penalización {penalty.upper()} ---")

    # Crear y entrenar el modelo
    model = LogisticRegression(penalty=penalty, solver='liblinear', C=1/lambda_value, max_iter=1000)
    model.fit(X_train04_sc, y_train04)

    # Predecir los valores en el conjunto de prueba
    y_pred = model.predict(X_test04_sc)
    y_pred_prob = model.predict_proba(X_test04_sc)[:, 1]

    # Calcular métricas
    acc = accuracy_score(y_test04, y_pred)
    auc = roc_auc_score(y_test04, y_pred_prob)
    cm = confusion_matrix(y_test04, y_pred)

    # Imprimir métricas
    print(f"Accuracy: {acc:.4f}")
    print(f"AUC: {auc:.4f}")
    print("Matriz de Confusión:")
    print(cm)

    # Configurar la figura para mostrar gráficos lado a lado
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Matriz de Confusión
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
    disp.plot(cmap='Blues', ax=axes[0], colorbar=False)
    axes[0].set_title(f"Matriz de Confusión - Penalización {penalty.upper()}")

    # Curva ROC
    fpr, tpr, _ = roc_curve(y_test04, y_pred_prob)
    axes[1].plot(fpr, tpr, label=f"AUC = {auc:.4f}")
    axes[1].plot([0, 1], [0, 1], 'k--', label="Random Guess")
    axes[1].set_xlabel("False Positive Rate")
    axes[1].set_ylabel("True Positive Rate")
    axes[1].set_title(f"Curva ROC - Penalización {penalty.upper()}")
    axes[1].legend()
    axes[1].grid()

    # Mostrar los gráficos
    plt.tight_layout()
    plt.show()

# Crear el escalador
sc = StandardScaler()

# Escalar sin usar índices ni columnas
X_train24_sc = pd.DataFrame(sc.fit_transform(X_train24))
X_test24_sc = pd.DataFrame(sc.transform(X_test24))

# Parámetros comunes
penalizaciones = ['l1', 'l2']  # L1 y L2
lambda_value = 1  # Corresponde a 'C = 1/lambda' en scikit-learn

for penalty in penalizaciones:
    print(f"\n--- Regresión Logística con Penalización {penalty.upper()} ---")

    # Crear y entrenar el modelo
    model24 = LogisticRegression(penalty=penalty, solver='liblinear', C=1/lambda_value, max_iter=1000)
    model24.fit(X_train24_sc, y_train24)

    # Predecir los valores en el conjunto de prueba
    y_pred24 = model24.predict(X_test24_sc)
    y_pred_prob24 = model24.predict_proba(X_test24_sc)[:, 1]

    # Calcular métricas
    acc = accuracy_score(y_test24, y_pred24)
    auc = roc_auc_score(y_test24, y_pred_prob24)
    cm = confusion_matrix(y_test24, y_pred24)

    # Imprimir métricas
    print(f"Accuracy: {acc:.4f}")
    print(f"AUC: {auc:.4f}")
    print("Matriz de Confusión:")
    print(cm)

    # Configurar la figura para gráficos lado a lado
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Matriz de Confusión
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model24.classes_)
    disp.plot(cmap='Blues', ax=axes[0], colorbar=False)
    axes[0].set_title(f"Matriz de Confusión - Penalización {penalty.upper()}")

    # Curva ROC
    fpr, tpr, _ = roc_curve(y_test24, y_pred_prob24)
    axes[1].plot(fpr, tpr, label=f"AUC = {auc:.4f}")
    axes[1].plot([0, 1], [0, 1], 'k--', label="Random Guess")
    axes[1].set_xlabel("False Positive Rate")
    axes[1].set_ylabel("True Positive Rate")
    axes[1].set_title(f"Curva ROC - Penalización {penalty.upper()}")
    axes[1].legend()
    axes[1].grid()

    # Ajustar el diseño y mostrar
    plt.tight_layout()
    plt.show()

"""## Ejercicio 5

"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score, KFold

"""#### 2004"""

# Valores de λ (lambda)
lambdas = [10**n for n in range(-6, 6)]
C_values = [1 / lambda_value for lambda_value in lambdas]

# 5-fold Cross-Validation
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Función para calcular el MSE en cada partición
def calcular_mse(estimator, X, y):
    scores = cross_val_score(estimator, X, y, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)
    return -scores  # Cambiamos el signo porque scikit-learn devuelve MSE negativo

mse_ridge04 = []
mse_lasso04 = []
proporcion_ceros_lasso04 = []

# Iteramos sobre los valores de C
for C in C_values:
    # Ridge (L2)
    model_ridge04 = LogisticRegression(penalty='l2', C=C, solver='saga', max_iter=1000)
    mse_ridge04.append(calcular_mse(model_ridge04, X_train04_sc, y_train04))

    # LASSO (L1)
    model_lasso04 = LogisticRegression(penalty='l1', C=C, solver='saga', max_iter=1000)
    model_lasso04.fit(X_train04_sc, y_train04)
    mse_lasso04.append(calcular_mse(model_lasso04, X_train04_sc, y_train04))

    # Calculamos la proporción de coeficientes cero
    proporciones_cero04 = np.mean(model_lasso04.coef_ == 0)
    proporcion_ceros_lasso04.append(proporciones_cero04)

# Selección del λ óptimo (el de menor MSE promedio)
mean_mse_ridge04 = [np.mean(mse) for mse in mse_ridge04]
mean_mse_lasso04 = [np.mean(mse) for mse in mse_lasso04]

lambda_opt_ridge04 = lambdas[np.argmin(mean_mse_ridge04)]
lambda_opt_lasso04 = lambdas[np.argmin(mean_mse_lasso04)]

print(f"λ óptimo para Ridge (L2): {lambda_opt_ridge04}")
print(f"λ óptimo para LASSO (L1): {lambda_opt_lasso04}")

# Generación de Box Plots para MSE
plt.figure(figsize=(12, 6))  # Aumentamos el tamaño general de la figura

# Paletas de colores personalizadas
palette_ridge = ['#1f77b4']
palette_lasso = ['#ff7f0e']

# Box plot para Ridge
plt.subplot(1, 2, 1)
sns.boxplot(data=mse_ridge04, orient='v', palette=palette_ridge)
plt.xticks(ticks=range(len(lambdas)), labels=[f"10^{n}" for n in range(-6, 6)], rotation=45)
plt.title("Distribución del MSE - Ridge (L2) para 2004")
plt.xlabel("λ (log10)")
plt.ylabel("MSE")

# Box plot para LASSO
plt.subplot(1, 2, 2)
sns.boxplot(data=mse_lasso04, orient='v', palette=palette_lasso)
plt.xticks(ticks=range(len(lambdas)), labels=[f"10^{n}" for n in range(-6, 6)], rotation=45)
plt.title("Distribución del MSE - LASSO (L1) para 2004")
plt.xlabel("λ (log10)")
plt.ylabel("MSE")

# Ajuste del layout para mejor presentación
plt.tight_layout()
plt.show()

# Generación de Line Plot para Proporción de Coeficientes Cero en LASSO
plt.figure(figsize=(8, 6))

# Usamos un color personalizado para la línea
sns.lineplot(x=[f"10^{n}" for n in range(-6, 6)], y=proporcion_ceros_lasso04, marker='.', color='#2ca02c')  # Verde para LASSO
plt.title("Proporción de Coeficientes Cero en LASSO para 2004")
plt.xlabel("λ (log10)")
plt.ylabel("Proporción de Coeficientes Cero")
plt.grid(True)

# Ajuste del layout para el line plot
plt.tight_layout()
plt.show()

"""#### 2024"""

# Valores de λ (lambda)
lambdas = [10**n for n in range(-6, 6)]  # n va entre -5 a 5 no toma los bordes

# 10-fold Cross-Validation
cv = KFold(n_splits=10, shuffle=True, random_state=42)

# Función para calcular el MSE en cada partición
def calcular_mse(estimator, X, y):
    scores = cross_val_score(estimator, X, y, cv=cv, scoring='neg_mean_squared_error')
    return -scores  # Cambiamos el signo porque scikit-learn devuelve MSE negativo

# creamos arrays para guardar resultados
mse_ridge24 = []
mse_lasso24 = []
proporcion_ceros_lasso24 = [] # cuantos coeficientes son cero

# Iteramos sobre los valores de lambda
for lambda_value in lambdas:
    C = 1 / lambda_value  # En LogisticRegression, C es el inverso de λ

    # Ridge (L2)
    model_ridge24 = LogisticRegression(penalty='l2', C=C, solver='liblinear', max_iter=1000)
    mse_ridge24.append(calcular_mse(model_ridge24, X_train24_sc, y_train24))

    # LASSO (L1)
    model_lasso24 = LogisticRegression(penalty='l1', C=C, solver='liblinear', max_iter=1000)
    mse_lasso24.append(calcular_mse(model_lasso24, X_train24_sc, y_train24))

    # Calculamos la proporción de coeficientes cero en LASSO
    model_lasso24.fit(X_train24_sc, y_train24)
    proporciones_cero24 = np.mean(model_lasso24.coef_ == 0)
    proporcion_ceros_lasso24.append(proporciones_cero24)

# Selección del λ óptimo (el de menor MSE promedio)
mean_mse_ridge24 = [np.mean(mse) for mse in mse_ridge24]
mean_mse_lasso24 = [np.mean(mse) for mse in mse_lasso24]

lambda_opt_ridge24 = lambdas[np.argmin(mean_mse_ridge24)]
lambda_opt_lasso24 = lambdas[np.argmin(mean_mse_lasso24)]

print(f"λ óptimo para Ridge (L2): {lambda_opt_ridge24}")
print(f"λ óptimo para LASSO (L1): {lambda_opt_lasso24}")

# Colores personalizados
ridge_color = "skyblue"
lasso_color = "salmon"
line_color = "purple"

# Generación de Box Plots para MSE
plt.figure(figsize=(12, 6))

# Box plot para Ridge
plt.subplot(1, 2, 1)
sns.boxplot(data=mse_ridge24, orient='v', color=ridge_color)
plt.xticks(ticks=range(len(lambdas)), labels=[f"10^{n}" for n in range(-5, 7)], rotation=45)
plt.title("Distribución del MSE - Ridge (L2)", fontsize=14)
plt.xlabel("λ (log10)", fontsize=12)
plt.ylabel("MSE", fontsize=12)

# Box plot para LASSO
plt.subplot(1, 2, 2)
sns.boxplot(data=mse_lasso24, orient='v', color=lasso_color)
plt.xticks(ticks=range(len(lambdas)), labels=[f"10^{n}" for n in range(-5, 7)], rotation=45)
plt.title("Distribución del MSE - LASSO (L1)", fontsize=14)
plt.xlabel("λ (log10)", fontsize=12)
plt.ylabel("MSE", fontsize=12)

plt.tight_layout()
plt.show()

# Generación de Line Plot para Proporción de Coeficientes Cero en LASSO
plt.figure(figsize=(8, 6))
sns.lineplot(x=[f"10^{n}" for n in range(-5, 7)], y=proporcion_ceros_lasso24, marker='o', color=line_color)
plt.title("Proporción de Coeficientes Cero en LASSO", fontsize=14)
plt.xlabel("λ (log10)", fontsize=12)
plt.ylabel("Proporción de Coeficientes Cero", fontsize=12)
plt.grid(color='gray', linestyle='--', linewidth=0.5)
plt.show()

"""## Ejercicio 6"""

# varibles con coeficiente 0 para LASSO

var_lasso = []
variables_cero = X_train24_sc.columns[model_lasso24.coef_[0] == 0]
var_lasso.append(variables_cero)

# Para guardarlo en un dataframe.
coeficientes_finales = pd.DataFrame([np.array(X_train24_sc.columns.tolist()),lasso.coef_]).T
coeficientes_finales.columns = ['feature','coeficiente']
print(f"El modelo final cuenta con: {coeficientes_finales[coeficientes_finales['coeficiente']!=0].shape[0]}",'features' )
coeficientes_finales

"""### Ejercicio 7

"""

print("Error cuadrático medio con Ridge 2004: ",mean_squared_error(y_test04, model_ridge04))
print("Error cuadrático medio con Lasso 2004: ",mean_squared_error(y_test04, model_lasso04))

print("Error cuadrático medio con Ridge 2024: ", mean_squared_error(y_test24, model_ridge24))
print("Error cuadrático medio con Lasso 2024: ", mean_squared_error(y_test24, model_lasso24))